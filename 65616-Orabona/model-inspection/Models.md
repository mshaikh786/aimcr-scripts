# Models Mentioned in the Proposal

## ⚠️ No Explicit AI / LLM Models Named

### AI Models – Domain-Specific, Unspecified Architectures

**Family:** Not specified  
**Documentation / Code Links:**  
_Not provided in the proposal_

---

## 1. Source / Provenance

### 1.1 Where is it coming from?

The proposal does **not name any specific AI, LLM, or foundation-model architectures**.  
Instead, it describes training a custom bilingual Arabic/English LLM from scratch. 

### 1.2 Who owns it?

Because no concrete models are specified:

- **Ownership:** Not specified  
- **Licensing:** Not specified  
- **Model origin:** Assumed to be open-source or commonly used research/industry models  

---

## 2. Model Characteristics

### 2.1 Number of Trainable Parameters

- Expected 3B parameters. 


### 2.2 Compute / MFU

- Substantial GPU resources are requested
- 375,000 GPU core hours requested.
- 1 - 2 CPU nodes requested.
- 96 GPU nodes requested.
- Compute justification is attributed to:
  - Large-scale simulations  
  - Data preprocessing and post-processing  
  - Repeated ML-assisted analysis  

No MFU reported.

---
