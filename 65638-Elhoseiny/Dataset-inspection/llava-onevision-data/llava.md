# RoboMIND

## Maintainer / Author

**Maintainer (dataset distributor):**  
Hugging Face organization *lmms-lab**  
https://huggingface.co/lmms-lab

**Affiliated organization:**  
**EvolvingLMMs-Lab** ( Singapore)  
https://github.com/EvolvingLMMs-Lab

---

## Artifact Related to a Paper

**Yes.**  
The dataset is accompanied by two papers:

> **LLaVA-OneVision: Easy Visual Task Transfer**

- Available on arXiv: https://arxiv.org/abs/2408.03326

and

> **UReader: Universal OCR-free Visually-situated Language Understanding with Multimodal Large Language Model**

- Available on arXiv: https://arxiv.org/abs/2310.05126

---

## Maintainer’s Public Presence

- Hugging Face organization page:  
  https://huggingface.co/X-Humanoid

- Official project website (GitHub Pages):  
  https://github.com/x-humanoid-robomind/x-humanoid-robomind.github.io

  https://x-humanoid-robomind.github.io/

- Academic presence via peer-reviewed publication (RSS 2025, arXiv)

---

## Dataset Source / Provenance

**Primary dataset URL (Hugging Face):**  
https://huggingface.co/datasets/x-humanoid-robomind/RoboMIND

**GitHub repository (project website & documentation):**  
https://github.com/x-humanoid-robomind/x-humanoid-robomind.github.io

---

## Repository Metadata

- **Last commit:** ~7 months ago (as of 17/12/25)

### Repository activity

- **Source page:** https://huggingface.co/datasets/lmms-lab/LLaVA-OneVision-Data/tree/main
- **Commits**: 135
- **Downloads:** Downloads last month 22,174 (as of 17/12/25)

---

## License Conditions

- **License:** Apache License 2.0 (Apache-2.0)

- **Permissibility:**
    - Permitted for **academic research and educational use**
    - Permitted for **commercial use**, **modification**, and **redistribution** under Apache-2.0 terms

- **Distribution Requirements:**
    - Any redistribution (original or modified) **must include**:
        - A copy of the **Apache-2.0 license**
        - Preservation of **copyright notices**
        - Preservation of any **NOTICE** files, if provided
    - Modifications must be clearly stated (no misrepresentation of original work)

- **Attribution:**
    - Attribution to the original authors and dataset maintainers is required
    - Citation of the associated project or paper is recommended for academic use

- **Warranty & Liability:**
    - Provided **“AS IS”**, without warranties or guarantees
    - Authors and contributors are **not liable** for downstream use

- **Additional Usage Notes (Dataset Card):**
    - The dataset card explicitly states usage is intended for **academic research and education**
    - Users are responsible for ensuring compliance with any **upstream data sources** included in specific subsets

> Includes human medical health datasets

---

## Dataset Inspection

LLaVA-OneVision-Data is a curated aggregation of **~90 heterogeneous vision-language datasets**, exposed as individual
Hugging Face configurations and unified under a LLaVA-style conversation format.

Inspection jupyter is too big to push to github but can be found at /ibex/project/c2320/dataset-check/lava-onevision-dataset/llava-onevision-data.ipynb 

